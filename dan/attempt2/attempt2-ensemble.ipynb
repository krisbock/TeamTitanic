{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    }
   ],
   "source": [
    "from theano.sandbox import cuda\n",
    "cuda.use('gpu0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import utils; reload(utils)\n",
    "from utils import *\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"data/icebergs/\"\n",
    "model_path = path + 'models/'\n",
    "if not os.path.exists(model_path): os.mkdir(model_path)\n",
    "\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1404 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', shuffle=False, batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1404 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 8424 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we're going to create an ensemble of models and use their average as our predictions. For each ensemble, we're going to follow our usual fine-tuning steps:\n",
    "\n",
    "1) Create a model that retrains just the last layer\n",
    "2) Add this to a model containing all VGG layers except the last layer\n",
    "3) Fine-tune just the dense layers of this model (pre-computing the convolutional layers)\n",
    "4) Add data augmentation, fine-tuning the dense layers without pre-computation.\n",
    "\n",
    "So first, we need to create our VGG model and pre-compute the output of the conv layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://files.fast.ai/models/vgg16_bn.h5\n",
      "553484288/553620808 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model = Vgg16BN().model\n",
    "conv_layers,fc_layers = split_at(model, Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_features = conv_model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "trn_features = conv_model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'train_convlayer_features.bc', trn_features)\n",
    "save_array(model_path + 'valid_convlayer_features.bc', val_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future we can just load these precomputed features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_features = load_array(model_path+'train_convlayer_features.bc')\n",
    "val_features = load_array(model_path+'valid_convlayer_features.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save some time by pre-computing the training and validation arrays with the image decoding and resizing already done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1404 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trn = get_data(path+'train')\n",
    "val = get_data(path+'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path+'train_data.bc', trn)\n",
    "save_array(model_path+'valid_data.bc', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the future we can just load these resized images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn = load_array(model_path+'train_data.bc')\n",
    "val = load_array(model_path+'valid_data.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can precompute the output of all but the last dropout and dense layers, for creating the first stage of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "model.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_val_feat = model.predict_generator(val_batches, val_batches.nb_sample)\n",
    "ll_feat = model.predict_generator(batches, batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(model_path + 'train_ll_feat.bc', ll_feat)\n",
    "save_array(model_path + 'valid_ll_feat.bc', ll_val_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ll_feat = load_array(model_path+ 'train_ll_feat.bc')\n",
    "ll_val_feat = load_array(model_path + 'valid_ll_feat.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and let's also grab the test data, for when we need to submit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8424 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test = get_data(path+'test')\n",
    "save_array(model_path+'test_data.bc', test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = load_array(model_path+'test_data.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The functions automate creating a model that trains the last layer from scratch, and then adds those new layers on to the main model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ll_layers():\n",
    "    return [ \n",
    "        BatchNormalization(input_shape=(4096,)),\n",
    "        Dropout(0.5),\n",
    "        Dense(2, activation='softmax') \n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_last_layer(i):\n",
    "    ll_layers = get_ll_layers()\n",
    "    ll_model = Sequential(ll_layers)\n",
    "    ll_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    ll_model.optimizer.lr=1e-5\n",
    "    ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=12)\n",
    "    ll_model.optimizer.lr=1e-7\n",
    "    ll_model.fit(ll_feat, trn_labels, validation_data=(ll_val_feat, val_labels), nb_epoch=1)\n",
    "    ll_model.save_weights(model_path+'ll_bn' + i + '.h5')\n",
    "\n",
    "    vgg = Vgg16BN()\n",
    "    model = vgg.model\n",
    "    model.pop(); model.pop(); model.pop()\n",
    "    for layer in model.layers: layer.trainable=False\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    ll_layers = get_ll_layers()\n",
    "    for layer in ll_layers: model.add(layer)\n",
    "    for l1,l2 in zip(ll_model.layers, model.layers[-3:]):\n",
    "        l2.set_weights(l1.get_weights())\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.save_weights(model_path+'bn' + i + '.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_conv_model(model):\n",
    "    layers = model.layers\n",
    "    last_conv_idx = [index for index,layer in enumerate(layers) \n",
    "                         if type(layer) is Convolution2D][-1]\n",
    "\n",
    "    conv_layers = layers[:last_conv_idx+1]\n",
    "    conv_model = Sequential(conv_layers)\n",
    "    fc_layers = layers[last_conv_idx+1:]\n",
    "    return conv_model, fc_layers, last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fc_layers(p, in_shape):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=in_shape),\n",
    "        Flatten(),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(4096, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(2, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_dense_layers(i, model):\n",
    "    conv_model, fc_layers, last_conv_idx = get_conv_model(model)\n",
    "    conv_shape = conv_model.output_shape[1:]\n",
    "    fc_model = Sequential(get_fc_layers(0.5, conv_shape))\n",
    "    for l1,l2 in zip(fc_model.layers, fc_layers): \n",
    "        weights = l2.get_weights()\n",
    "        l1.set_weights(weights)\n",
    "    fc_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])\n",
    "    fc_model.fit(trn_features, trn_labels, nb_epoch=2, \n",
    "         batch_size=batch_size, validation_data=(val_features, val_labels))\n",
    "\n",
    "    gen = image.ImageDataGenerator(rotation_range=10, width_shift_range=0.05, zoom_range=0.05, channel_shift_range=10, height_shift_range=0.05, shear_range=0.05, horizontal_flip=True)\n",
    "    \n",
    "        \n",
    "    batches = gen.flow(trn, trn_labels, batch_size=batch_size)\n",
    "    val_batches = image.ImageDataGenerator().flow(val, val_labels, \n",
    "                      shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    for layer in conv_model.layers: layer.trainable = False\n",
    "    for layer in get_fc_layers(0.5, conv_shape): conv_model.add(layer)\n",
    "    for l1,l2 in zip(conv_model.layers[last_conv_idx+1:], fc_model.layers): \n",
    "        l1.set_weights(l2.get_weights())\n",
    "\n",
    "    conv_model.compile(optimizer=Adam(1e-5), loss='categorical_crossentropy', \n",
    "                       metrics=['accuracy'])\n",
    "    conv_model.save_weights(model_path+'no_dropout_bn' + i + '.h5')\n",
    "    conv_model.fit_generator(batches, samples_per_epoch=batches.N, nb_epoch=1, \n",
    "                            validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    for layer in conv_model.layers[16:]: layer.trainable = True\n",
    "    conv_model.fit_generator(batches, samples_per_epoch=batches.N, nb_epoch=8, \n",
    "                            validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "\n",
    "    conv_model.optimizer.lr = 1e-7\n",
    "    conv_model.fit_generator(batches, samples_per_epoch=batches.N, nb_epoch=10, \n",
    "                            validation_data=val_batches, nb_val_samples=val_batches.N)\n",
    "    conv_model.save_weights(model_path + 'aug' + i + '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Build ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.1407 - acc: 0.5242 - val_loss: 0.9654 - val_acc: 0.4200\n",
      "Epoch 2/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0440 - acc: 0.5726 - val_loss: 0.9836 - val_acc: 0.4100\n",
      "Epoch 3/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9935 - acc: 0.5698 - val_loss: 1.0313 - val_acc: 0.3850\n",
      "Epoch 4/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0031 - acc: 0.5798 - val_loss: 1.0929 - val_acc: 0.3500\n",
      "Epoch 5/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9490 - acc: 0.5805 - val_loss: 1.1611 - val_acc: 0.3350\n",
      "Epoch 6/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9117 - acc: 0.6075 - val_loss: 1.2192 - val_acc: 0.3250\n",
      "Epoch 7/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9290 - acc: 0.5919 - val_loss: 1.2941 - val_acc: 0.3200\n",
      "Epoch 8/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8678 - acc: 0.6075 - val_loss: 1.3512 - val_acc: 0.3300\n",
      "Epoch 9/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8305 - acc: 0.6481 - val_loss: 1.3940 - val_acc: 0.3300\n",
      "Epoch 10/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9033 - acc: 0.5947 - val_loss: 1.4313 - val_acc: 0.3350\n",
      "Epoch 11/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8424 - acc: 0.6161 - val_loss: 1.4754 - val_acc: 0.3300\n",
      "Epoch 12/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8461 - acc: 0.6239 - val_loss: 1.4916 - val_acc: 0.3400\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 0s - loss: 0.8218 - acc: 0.6325 - val_loss: 1.5171 - val_acc: 0.3350\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.9393 - acc: 0.6360 - val_loss: 1.1472 - val_acc: 0.6200\n",
      "Epoch 2/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.5166 - acc: 0.7906 - val_loss: 0.5461 - val_acc: 0.7450\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 54s - loss: 0.7381 - acc: 0.7208 - val_loss: 0.5201 - val_acc: 0.7550\n",
      "Epoch 1/8\n",
      "1404/1404 [==============================] - 54s - loss: 0.7967 - acc: 0.6923 - val_loss: 0.4789 - val_acc: 0.7550\n",
      "Epoch 2/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5819 - acc: 0.7628 - val_loss: 0.4862 - val_acc: 0.7450\n",
      "Epoch 3/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6264 - acc: 0.7585 - val_loss: 0.4679 - val_acc: 0.7500\n",
      "Epoch 4/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5536 - acc: 0.7728 - val_loss: 0.4947 - val_acc: 0.7500\n",
      "Epoch 5/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5701 - acc: 0.7664 - val_loss: 0.4827 - val_acc: 0.7700\n",
      "Epoch 6/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5671 - acc: 0.7692 - val_loss: 0.4982 - val_acc: 0.7600\n",
      "Epoch 7/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5252 - acc: 0.7877 - val_loss: 0.4619 - val_acc: 0.7950\n",
      "Epoch 8/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5002 - acc: 0.7927 - val_loss: 0.4449 - val_acc: 0.8000\n",
      "Epoch 1/10\n",
      "1404/1404 [==============================] - 54s - loss: 0.5074 - acc: 0.7991 - val_loss: 0.4268 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5018 - acc: 0.7963 - val_loss: 0.4153 - val_acc: 0.8050\n",
      "Epoch 3/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5767 - acc: 0.7849 - val_loss: 0.4171 - val_acc: 0.7750\n",
      "Epoch 4/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4394 - acc: 0.8305 - val_loss: 0.4145 - val_acc: 0.8200\n",
      "Epoch 5/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4758 - acc: 0.7970 - val_loss: 0.4416 - val_acc: 0.8000\n",
      "Epoch 6/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5025 - acc: 0.8020 - val_loss: 0.4262 - val_acc: 0.7800\n",
      "Epoch 7/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4628 - acc: 0.8034 - val_loss: 0.4048 - val_acc: 0.8050\n",
      "Epoch 8/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4714 - acc: 0.8084 - val_loss: 0.4057 - val_acc: 0.8200\n",
      "Epoch 9/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4625 - acc: 0.8155 - val_loss: 0.4237 - val_acc: 0.7750\n",
      "Epoch 10/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4517 - acc: 0.8198 - val_loss: 0.4071 - val_acc: 0.8100\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.2123 - acc: 0.4843 - val_loss: 0.9933 - val_acc: 0.4950\n",
      "Epoch 2/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.1543 - acc: 0.4872 - val_loss: 0.9573 - val_acc: 0.4650\n",
      "Epoch 3/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0253 - acc: 0.5491 - val_loss: 0.9740 - val_acc: 0.3900\n",
      "Epoch 4/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0300 - acc: 0.5442 - val_loss: 1.0100 - val_acc: 0.3650\n",
      "Epoch 5/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9662 - acc: 0.5812 - val_loss: 1.0651 - val_acc: 0.3550\n",
      "Epoch 6/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9343 - acc: 0.6061 - val_loss: 1.1297 - val_acc: 0.3550\n",
      "Epoch 7/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9265 - acc: 0.5897 - val_loss: 1.1926 - val_acc: 0.3450\n",
      "Epoch 8/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9085 - acc: 0.5969 - val_loss: 1.2544 - val_acc: 0.3550\n",
      "Epoch 9/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9739 - acc: 0.5826 - val_loss: 1.3135 - val_acc: 0.3450\n",
      "Epoch 10/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8969 - acc: 0.6004 - val_loss: 1.3658 - val_acc: 0.3450\n",
      "Epoch 11/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8806 - acc: 0.6147 - val_loss: 1.4195 - val_acc: 0.3450\n",
      "Epoch 12/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8627 - acc: 0.6168 - val_loss: 1.4614 - val_acc: 0.3600\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 0s - loss: 0.8932 - acc: 0.6211 - val_loss: 1.4904 - val_acc: 0.3600\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.8929 - acc: 0.6360 - val_loss: 0.5533 - val_acc: 0.7650\n",
      "Epoch 2/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.5638 - acc: 0.7749 - val_loss: 0.4406 - val_acc: 0.7850\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 54s - loss: 0.7106 - acc: 0.7279 - val_loss: 0.5883 - val_acc: 0.7400\n",
      "Epoch 1/8\n",
      "1404/1404 [==============================] - 54s - loss: 0.7027 - acc: 0.7350 - val_loss: 0.4357 - val_acc: 0.7700\n",
      "Epoch 2/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6667 - acc: 0.7443 - val_loss: 0.4272 - val_acc: 0.7700\n",
      "Epoch 3/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6209 - acc: 0.7422 - val_loss: 0.4228 - val_acc: 0.7800\n",
      "Epoch 4/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5796 - acc: 0.7671 - val_loss: 0.4658 - val_acc: 0.7900\n",
      "Epoch 5/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5829 - acc: 0.7728 - val_loss: 0.4224 - val_acc: 0.7800\n",
      "Epoch 6/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6155 - acc: 0.7721 - val_loss: 0.4274 - val_acc: 0.7750\n",
      "Epoch 7/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5904 - acc: 0.7721 - val_loss: 0.4019 - val_acc: 0.8150\n",
      "Epoch 8/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5256 - acc: 0.7885 - val_loss: 0.4444 - val_acc: 0.7650\n",
      "Epoch 1/10\n",
      "1404/1404 [==============================] - 54s - loss: 0.5192 - acc: 0.7849 - val_loss: 0.4213 - val_acc: 0.8050\n",
      "Epoch 2/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5334 - acc: 0.7685 - val_loss: 0.4115 - val_acc: 0.8000\n",
      "Epoch 3/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5322 - acc: 0.7842 - val_loss: 0.4470 - val_acc: 0.7750\n",
      "Epoch 4/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5353 - acc: 0.7835 - val_loss: 0.4265 - val_acc: 0.7950\n",
      "Epoch 5/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5221 - acc: 0.7813 - val_loss: 0.4237 - val_acc: 0.7850\n",
      "Epoch 6/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4788 - acc: 0.8077 - val_loss: 0.4073 - val_acc: 0.7950\n",
      "Epoch 7/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4706 - acc: 0.8234 - val_loss: 0.4431 - val_acc: 0.8050\n",
      "Epoch 8/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4867 - acc: 0.8020 - val_loss: 0.4289 - val_acc: 0.7950\n",
      "Epoch 9/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4785 - acc: 0.8127 - val_loss: 0.4107 - val_acc: 0.7950\n",
      "Epoch 10/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4462 - acc: 0.8127 - val_loss: 0.4298 - val_acc: 0.7950\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.1200 - acc: 0.5264 - val_loss: 0.9700 - val_acc: 0.4050\n",
      "Epoch 2/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0363 - acc: 0.5613 - val_loss: 1.0137 - val_acc: 0.4150\n",
      "Epoch 3/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9896 - acc: 0.5890 - val_loss: 1.0719 - val_acc: 0.3950\n",
      "Epoch 4/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9610 - acc: 0.5705 - val_loss: 1.1288 - val_acc: 0.3900\n",
      "Epoch 5/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9370 - acc: 0.5862 - val_loss: 1.1844 - val_acc: 0.3600\n",
      "Epoch 6/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9453 - acc: 0.5848 - val_loss: 1.2490 - val_acc: 0.3400\n",
      "Epoch 7/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9042 - acc: 0.6211 - val_loss: 1.2951 - val_acc: 0.3250\n",
      "Epoch 8/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9076 - acc: 0.6047 - val_loss: 1.3392 - val_acc: 0.3300\n",
      "Epoch 9/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8705 - acc: 0.6168 - val_loss: 1.3863 - val_acc: 0.3200\n",
      "Epoch 10/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9040 - acc: 0.6011 - val_loss: 1.4304 - val_acc: 0.3250\n",
      "Epoch 11/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8631 - acc: 0.6517 - val_loss: 1.4755 - val_acc: 0.3300\n",
      "Epoch 12/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8435 - acc: 0.6303 - val_loss: 1.5090 - val_acc: 0.3300\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 0s - loss: 0.8521 - acc: 0.6204 - val_loss: 1.5436 - val_acc: 0.3350\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.9702 - acc: 0.6303 - val_loss: 1.9218 - val_acc: 0.5800\n",
      "Epoch 2/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.5794 - acc: 0.7699 - val_loss: 0.9278 - val_acc: 0.6700\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 54s - loss: 0.7708 - acc: 0.6973 - val_loss: 0.5662 - val_acc: 0.7100\n",
      "Epoch 1/8\n",
      "1404/1404 [==============================] - 54s - loss: 0.6631 - acc: 0.7464 - val_loss: 0.5126 - val_acc: 0.7400\n",
      "Epoch 2/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6753 - acc: 0.7358 - val_loss: 0.4541 - val_acc: 0.7750\n",
      "Epoch 3/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6539 - acc: 0.7486 - val_loss: 0.4325 - val_acc: 0.8050\n",
      "Epoch 4/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6126 - acc: 0.7692 - val_loss: 0.4258 - val_acc: 0.7850\n",
      "Epoch 5/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6124 - acc: 0.7557 - val_loss: 0.4086 - val_acc: 0.8000\n",
      "Epoch 6/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6107 - acc: 0.7628 - val_loss: 0.4033 - val_acc: 0.7900\n",
      "Epoch 7/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5184 - acc: 0.7856 - val_loss: 0.4163 - val_acc: 0.7950\n",
      "Epoch 8/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5571 - acc: 0.7892 - val_loss: 0.4159 - val_acc: 0.8000\n",
      "Epoch 1/10\n",
      "1404/1404 [==============================] - 54s - loss: 0.5628 - acc: 0.7877 - val_loss: 0.3967 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5531 - acc: 0.7764 - val_loss: 0.3875 - val_acc: 0.8100\n",
      "Epoch 3/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5374 - acc: 0.7828 - val_loss: 0.3887 - val_acc: 0.8000\n",
      "Epoch 4/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4965 - acc: 0.7920 - val_loss: 0.3921 - val_acc: 0.7950\n",
      "Epoch 5/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5543 - acc: 0.7913 - val_loss: 0.4041 - val_acc: 0.7900\n",
      "Epoch 6/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5048 - acc: 0.7870 - val_loss: 0.4107 - val_acc: 0.7550\n",
      "Epoch 7/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4585 - acc: 0.8155 - val_loss: 0.4006 - val_acc: 0.7900\n",
      "Epoch 8/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4787 - acc: 0.8127 - val_loss: 0.3973 - val_acc: 0.8000\n",
      "Epoch 9/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4536 - acc: 0.8226 - val_loss: 0.4365 - val_acc: 0.8150\n",
      "Epoch 10/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4740 - acc: 0.8170 - val_loss: 0.4422 - val_acc: 0.8250\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.2064 - acc: 0.4993 - val_loss: 0.8570 - val_acc: 0.5150\n",
      "Epoch 2/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0798 - acc: 0.5377 - val_loss: 0.8633 - val_acc: 0.5100\n",
      "Epoch 3/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0574 - acc: 0.5434 - val_loss: 0.9009 - val_acc: 0.4950\n",
      "Epoch 4/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0129 - acc: 0.5613 - val_loss: 0.9571 - val_acc: 0.4350\n",
      "Epoch 5/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9903 - acc: 0.5819 - val_loss: 1.0223 - val_acc: 0.4100\n",
      "Epoch 6/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9337 - acc: 0.5933 - val_loss: 1.0966 - val_acc: 0.3850\n",
      "Epoch 7/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8889 - acc: 0.6111 - val_loss: 1.1641 - val_acc: 0.3650\n",
      "Epoch 8/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9154 - acc: 0.5976 - val_loss: 1.2361 - val_acc: 0.3400\n",
      "Epoch 9/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9277 - acc: 0.6061 - val_loss: 1.3057 - val_acc: 0.3200\n",
      "Epoch 10/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8538 - acc: 0.6161 - val_loss: 1.3677 - val_acc: 0.3150\n",
      "Epoch 11/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8337 - acc: 0.6396 - val_loss: 1.4217 - val_acc: 0.3050\n",
      "Epoch 12/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8298 - acc: 0.6531 - val_loss: 1.4669 - val_acc: 0.3000\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 0s - loss: 0.8091 - acc: 0.6460 - val_loss: 1.5110 - val_acc: 0.3000\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.9465 - acc: 0.6410 - val_loss: 1.7558 - val_acc: 0.5800\n",
      "Epoch 2/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.5757 - acc: 0.7699 - val_loss: 0.8542 - val_acc: 0.6700\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 54s - loss: 0.7238 - acc: 0.7108 - val_loss: 0.5259 - val_acc: 0.7550\n",
      "Epoch 1/8\n",
      "1404/1404 [==============================] - 54s - loss: 0.6677 - acc: 0.7393 - val_loss: 0.4888 - val_acc: 0.7700\n",
      "Epoch 2/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6454 - acc: 0.7493 - val_loss: 0.4678 - val_acc: 0.7700\n",
      "Epoch 3/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6466 - acc: 0.7543 - val_loss: 0.4688 - val_acc: 0.7600\n",
      "Epoch 4/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6377 - acc: 0.7500 - val_loss: 0.4191 - val_acc: 0.7700\n",
      "Epoch 5/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5832 - acc: 0.7821 - val_loss: 0.4293 - val_acc: 0.7650\n",
      "Epoch 6/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5626 - acc: 0.7735 - val_loss: 0.4397 - val_acc: 0.7800\n",
      "Epoch 7/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5465 - acc: 0.7813 - val_loss: 0.4281 - val_acc: 0.7800\n",
      "Epoch 8/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5716 - acc: 0.7771 - val_loss: 0.4065 - val_acc: 0.7700\n",
      "Epoch 1/10\n",
      "1404/1404 [==============================] - 54s - loss: 0.5453 - acc: 0.7742 - val_loss: 0.4076 - val_acc: 0.7950\n",
      "Epoch 2/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5532 - acc: 0.7821 - val_loss: 0.4037 - val_acc: 0.8050\n",
      "Epoch 3/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5232 - acc: 0.7892 - val_loss: 0.3990 - val_acc: 0.7850\n",
      "Epoch 4/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5283 - acc: 0.7785 - val_loss: 0.4047 - val_acc: 0.8000\n",
      "Epoch 5/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5035 - acc: 0.7984 - val_loss: 0.3906 - val_acc: 0.7950\n",
      "Epoch 6/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4604 - acc: 0.8120 - val_loss: 0.4112 - val_acc: 0.8100\n",
      "Epoch 7/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5203 - acc: 0.7813 - val_loss: 0.4140 - val_acc: 0.7800\n",
      "Epoch 8/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4640 - acc: 0.8170 - val_loss: 0.4130 - val_acc: 0.7850\n",
      "Epoch 9/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4895 - acc: 0.8041 - val_loss: 0.4057 - val_acc: 0.8000\n",
      "Epoch 10/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4373 - acc: 0.8134 - val_loss: 0.4004 - val_acc: 0.7800\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0523 - acc: 0.5406 - val_loss: 1.9053 - val_acc: 0.5000\n",
      "Epoch 2/12\n",
      "1404/1404 [==============================] - 0s - loss: 1.0212 - acc: 0.5840 - val_loss: 1.4910 - val_acc: 0.4700\n",
      "Epoch 3/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9368 - acc: 0.5976 - val_loss: 1.3262 - val_acc: 0.3750\n",
      "Epoch 4/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9491 - acc: 0.5876 - val_loss: 1.2897 - val_acc: 0.3500\n",
      "Epoch 5/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9031 - acc: 0.6090 - val_loss: 1.3178 - val_acc: 0.3350\n",
      "Epoch 6/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.9239 - acc: 0.5883 - val_loss: 1.3683 - val_acc: 0.3300\n",
      "Epoch 7/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8789 - acc: 0.6182 - val_loss: 1.4111 - val_acc: 0.3500\n",
      "Epoch 8/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8564 - acc: 0.6303 - val_loss: 1.4531 - val_acc: 0.3500\n",
      "Epoch 9/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8445 - acc: 0.6353 - val_loss: 1.4838 - val_acc: 0.3600\n",
      "Epoch 10/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8134 - acc: 0.6353 - val_loss: 1.5161 - val_acc: 0.3550\n",
      "Epoch 11/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8924 - acc: 0.6083 - val_loss: 1.5541 - val_acc: 0.3600\n",
      "Epoch 12/12\n",
      "1404/1404 [==============================] - 0s - loss: 0.8729 - acc: 0.6211 - val_loss: 1.5885 - val_acc: 0.3600\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 0s - loss: 0.8166 - acc: 0.6353 - val_loss: 1.6157 - val_acc: 0.3600\n",
      "Train on 1404 samples, validate on 200 samples\n",
      "Epoch 1/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.9644 - acc: 0.6211 - val_loss: 0.9778 - val_acc: 0.6550\n",
      "Epoch 2/2\n",
      "1404/1404 [==============================] - 3s - loss: 0.5813 - acc: 0.7692 - val_loss: 0.6444 - val_acc: 0.7000\n",
      "Epoch 1/1\n",
      "1404/1404 [==============================] - 54s - loss: 0.7362 - acc: 0.7179 - val_loss: 0.4960 - val_acc: 0.7750\n",
      "Epoch 1/8\n",
      "1404/1404 [==============================] - 54s - loss: 0.6581 - acc: 0.7415 - val_loss: 0.5408 - val_acc: 0.7500\n",
      "Epoch 2/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6590 - acc: 0.7472 - val_loss: 0.5560 - val_acc: 0.7400\n",
      "Epoch 3/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6314 - acc: 0.7564 - val_loss: 0.4526 - val_acc: 0.7750\n",
      "Epoch 4/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.6010 - acc: 0.7621 - val_loss: 0.4403 - val_acc: 0.7750\n",
      "Epoch 5/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5975 - acc: 0.7714 - val_loss: 0.4503 - val_acc: 0.7750\n",
      "Epoch 6/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5789 - acc: 0.7728 - val_loss: 0.4536 - val_acc: 0.7650\n",
      "Epoch 7/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5706 - acc: 0.7721 - val_loss: 0.4715 - val_acc: 0.7750\n",
      "Epoch 8/8\n",
      "1404/1404 [==============================] - 53s - loss: 0.5673 - acc: 0.7927 - val_loss: 0.4370 - val_acc: 0.7800\n",
      "Epoch 1/10\n",
      "1404/1404 [==============================] - 54s - loss: 0.5666 - acc: 0.7806 - val_loss: 0.4498 - val_acc: 0.7650\n",
      "Epoch 2/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4884 - acc: 0.8020 - val_loss: 0.4493 - val_acc: 0.7600\n",
      "Epoch 3/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5468 - acc: 0.7842 - val_loss: 0.4554 - val_acc: 0.7800\n",
      "Epoch 4/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5329 - acc: 0.8041 - val_loss: 0.4656 - val_acc: 0.7800\n",
      "Epoch 5/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.5197 - acc: 0.7949 - val_loss: 0.4215 - val_acc: 0.7750\n",
      "Epoch 6/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4644 - acc: 0.8020 - val_loss: 0.4107 - val_acc: 0.7950\n",
      "Epoch 7/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4819 - acc: 0.8170 - val_loss: 0.4194 - val_acc: 0.8050\n",
      "Epoch 8/10\n",
      "1404/1404 [==============================] - 53s - loss: 0.4850 - acc: 0.8120 - val_loss: 0.4252 - val_acc: 0.7900\n",
      "Epoch 9/10\n",
      "1404/1404 [==============================] - 54s - loss: 0.4742 - acc: 0.8113 - val_loss: 0.4607 - val_acc: 0.7700\n",
      "Epoch 10/10\n",
      "1404/1404 [==============================] - 54s - loss: 0.5106 - acc: 0.7984 - val_loss: 0.4220 - val_acc: 0.7950\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    i = str(i)\n",
    "    model = train_last_layer(i)\n",
    "    train_dense_layers(i, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine ensemble and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ens_model = vgg_ft_bn(2)\n",
    "for layer in ens_model.layers: layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_ens_pred(arr, fname):\n",
    "    ens_pred = []\n",
    "    for i in range(5):\n",
    "        i = str(i)\n",
    "        ens_model.load_weights('{}{}{}.h5'.format(model_path, fname, i))\n",
    "        preds = ens_model.predict(arr, batch_size=batch_size)\n",
    "        ens_pred.append(preds)\n",
    "    return ens_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_pred2 = get_ens_pred(val, 'aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_avg_preds2 = np.stack(val_pred2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.8100000023841858, dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_accuracy(val_labels, val_avg_preds2).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our new model to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-9e800fba56f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ens_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aug'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "test_pred2 = get_ens_pred(test, 'aug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_avg_preds2 = np.stack(test_pred2).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.4137e-01,   8.5863e-01],\n",
       "       [  9.9559e-01,   4.4107e-03],\n",
       "       [  5.2689e-01,   4.7311e-01],\n",
       "       [  9.2740e-01,   7.2600e-02],\n",
       "       [  6.1630e-06,   9.9999e-01]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_avg_preds2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save our test results arrays so we can use them again later\n",
    "save_array(model_path + 'test_preds.dat', test_avg_preds2)\n",
    "save_array(model_path + 'filenames.dat', test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit Predictions to Kaggle!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the format Kaggle requires for new submissions:\n",
    "```\n",
    "id,is_iceberg\n",
    "5941774d,0.5\n",
    "4023181e,0.5\n",
    "b20200e4,0.5\n",
    "e7f018bb,0.5\n",
    "```\n",
    "\n",
    "Kaggle wants the imageId followed by the probability of the image being an iceberg. Kaggle uses a metric called [Log Loss](http://wiki.fast.ai/index.php/Log_Loss) to evaluate your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "preds=load_array(model_path + 'test_preds.dat')\n",
    "filenames=load_array(model_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isiceberg= preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isiceberg = isiceberg.clip(min=0.30, max=0.70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0e3eb3a9', '489fccbf', '6480ab5e', 'e103cde7', 'fdf9388b'], \n",
       "      dtype='|S8')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "ids = np.array([(f[8:f.find('.')]) for f in filenames])\n",
    "ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the two columns into an array of [ids, isceberg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0e3eb3a9', '0.699999988079'],\n",
       "       ['489fccbf', '0.300000011921'],\n",
       "       ['6480ab5e', '0.47310590744'],\n",
       "       ['e103cde7', '0.300000011921'],\n",
       "       ['fdf9388b', '0.699999988079']], \n",
       "      dtype='|S32')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subm = np.stack([ids,isiceberg], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/kaggle-iceberg/attempt2\n"
     ]
    }
   ],
   "source": [
    "%cd ~/kaggle-iceberg/attempt2\n",
    "submission_file_name = 'submission_ensemble3.csv'\n",
    "np.savetxt(submission_file_name, subm, delimiter=',', header='id,is_iceberg',fmt='%s', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='./submission_ensemble3.csv' target='_blank'>./submission_ensemble3.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/kaggle-iceberg/attempt2/submission_ensemble3.csv"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('./'+submission_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_8 (Lambda)                (None, 3, 224, 224)   0           lambda_input_8[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_92 (ZeroPadding2D) (None, 3, 226, 226)   0           lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_92 (Convolution2D) (None, 64, 224, 224)  0           zeropadding2d_92[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_93 (ZeroPadding2D) (None, 64, 226, 226)  0           convolution2d_92[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_93 (Convolution2D) (None, 64, 224, 224)  0           zeropadding2d_93[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_46 (MaxPooling2D)   (None, 64, 112, 112)  0           convolution2d_93[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_94 (ZeroPadding2D) (None, 64, 114, 114)  0           maxpooling2d_46[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_94 (Convolution2D) (None, 128, 112, 112) 0           zeropadding2d_94[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_95 (ZeroPadding2D) (None, 128, 114, 114) 0           convolution2d_94[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_95 (Convolution2D) (None, 128, 112, 112) 0           zeropadding2d_95[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_47 (MaxPooling2D)   (None, 128, 56, 56)   0           convolution2d_95[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_96 (ZeroPadding2D) (None, 128, 58, 58)   0           maxpooling2d_47[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_96 (Convolution2D) (None, 256, 56, 56)   0           zeropadding2d_96[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_97 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_96[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_97 (Convolution2D) (None, 256, 56, 56)   0           zeropadding2d_97[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_98 (ZeroPadding2D) (None, 256, 58, 58)   0           convolution2d_97[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_98 (Convolution2D) (None, 256, 56, 56)   590080      zeropadding2d_98[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_48 (MaxPooling2D)   (None, 256, 28, 28)   0           convolution2d_98[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_99 (ZeroPadding2D) (None, 256, 30, 30)   0           maxpooling2d_48[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_99 (Convolution2D) (None, 512, 28, 28)   1180160     zeropadding2d_99[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_100 (ZeroPadding2D)(None, 512, 30, 30)   0           convolution2d_99[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_100 (Convolution2D)(None, 512, 28, 28)   2359808     zeropadding2d_100[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_101 (ZeroPadding2D)(None, 512, 30, 30)   0           convolution2d_100[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_101 (Convolution2D)(None, 512, 28, 28)   2359808     zeropadding2d_101[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_49 (MaxPooling2D)   (None, 512, 14, 14)   0           convolution2d_101[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_102 (ZeroPadding2D)(None, 512, 16, 16)   0           maxpooling2d_49[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_102 (Convolution2D)(None, 512, 14, 14)   2359808     zeropadding2d_102[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_103 (ZeroPadding2D)(None, 512, 16, 16)   0           convolution2d_102[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_103 (Convolution2D)(None, 512, 14, 14)   2359808     zeropadding2d_103[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_104 (ZeroPadding2D)(None, 512, 16, 16)   0           convolution2d_103[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_104 (Convolution2D)(None, 512, 14, 14)   2359808     zeropadding2d_104[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_50 (MaxPooling2D)   (None, 512, 7, 7)     0           convolution2d_104[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 25088)         0           maxpooling2d_50[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_66 (Dense)                 (None, 4096)          0           flatten_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_49 (BatchNorma(None, 4096)          0           dense_66[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)             (None, 4096)          0           batchnormalization_49[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_67 (Dense)                 (None, 4096)          0           dropout_49[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "batchnormalization_51 (BatchNorma(None, 4096)          8192        dense_67[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)             (None, 4096)          0           batchnormalization_51[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dense_69 (Dense)                 (None, 2)             8194        dropout_51[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 13585666\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
